{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "4"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import mxnet as mx\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import data as gdata, loss as gloss, nn, utils as gutils\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import d2lzh as d2l\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_batch(batch, ctx):\n",
    "    features, labels = batch\n",
    "    if labels.dtype != features.dtype:\n",
    "        labels = labels.astype(features.dtype)\n",
    "    return (gutils.split_and_load(features, ctx),\n",
    "            gutils.split_and_load(labels, ctx), features.shape[0])\n",
    "\n",
    "def evaluate_accuracy(data_iter, net, ctx=[mx.cpu()]):\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    acc_sum, n = nd.array([0]), 0\n",
    "    for batch in data_iter:\n",
    "        features, labels, _ = _get_batch(batch, ctx)\n",
    "        for X, y in zip(features, labels):\n",
    "            y = y.astype('float32')\n",
    "            acc_sum += (net(X).argmax(axis=1) == y).sum().copyto(mx.cpu())\n",
    "            n += y.size\n",
    "        acc_sum.wait_to_read()\n",
    "    return acc_sum.asscalar() / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_CNN_class(train_iter, test_iter, net, loss, trainer, ctx, num_epochs,lr_period,lr_decay, end_con):\n",
    "    print('training on', ctx)\n",
    "    if isinstance(ctx, mx.Context):\n",
    "        ctx = [ctx]\n",
    "    for epoch in range(num_epochs):\n",
    "        train_l_sum, train_acc_sum, n, m, start = 0.0, 0.0, 0, 0, time.time()\n",
    "        if epoch > 0 and epoch % lr_period == 0:\n",
    "            trainer.set_learning_rate(trainer.learning_rate * lr_decay)\n",
    "        for i, batch in enumerate(train_iter):\n",
    "            Xs, ys, batch_size = _get_batch(batch, ctx)\n",
    "            ls = []\n",
    "            with autograd.record():\n",
    "                y_hats = [net(X) for X in Xs]\n",
    "                ls = [loss(y_hat, y) for y_hat, y in zip(y_hats, ys)]\n",
    "            for l in ls:\n",
    "                l.backward()\n",
    "            trainer.step(batch_size)\n",
    "            train_l_sum += sum([l.sum().asscalar() for l in ls])\n",
    "            n += sum([l.size for l in ls])       \n",
    "        train_acc = evaluate_accuracy(train_iter, net, ctx)\n",
    "        test_acc = evaluate_accuracy(test_iter, net, ctx)\n",
    "        print('epoch %d, loss %.7f,cal %.4f,val %.4f, lr %.7f, time %.1f sec'\n",
    "              % (epoch + 1, train_l_sum / n,train_acc, test_acc, trainer.learning_rate, time.time() - start))\n",
    "        if test_acc>end_con:break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "6"
    }
   },
   "outputs": [],
   "source": [
    "cal = pd.read_csv('DT_train.csv',header=None)\n",
    "val = pd.read_csv('DT_val.csv',header=None)\n",
    "pre = pd.read_csv('DT_test.csv',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "3"
    }
   },
   "outputs": [],
   "source": [
    "cal_features = cal.iloc[:, 0:-1]\n",
    "val_features = val.iloc[:, 0:-1]\n",
    "pre_features = pre.iloc[:, 0:-1]\n",
    "cal_labels = cal.iloc[:, -1]\n",
    "val_labels = val.iloc[:, -1]\n",
    "pre_labels = pre.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cal_features = nd.array(cal_features.values)\n",
    "val_features = nd.array(val_features.values)\n",
    "pre_features = nd.array(pre_features.values)\n",
    "\n",
    "cal_labels = nd.array(cal_labels.values)\n",
    "val_labels = nd.array(val_labels.values)\n",
    "pre_labels = nd.array(pre_labels.values)\n",
    "\n",
    "print(cal_features.shape,cal_labels.shape,val_features.shape,val_labels.shape,pre_features.shape,pre_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256\n",
    "\n",
    "train_iter = gdata.DataLoader(gdata.ArrayDataset(cal_features, cal_labels), batch_size, shuffle=True)\n",
    "val_iter  = gdata.DataLoader(gdata.ArrayDataset(val_features, val_labels), batch_size, shuffle=False)\n",
    "pre_iter  = gdata.DataLoader(gdata.ArrayDataset(pre_features, pre_labels), batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attension(nn.Block):\n",
    "    def __init__(self, c1, c2, **kwargs):\n",
    "        super(Attension, self).__init__(**kwargs)        \n",
    "        self.p1 = nn.Dense(c1, activation=\"tanh\")\n",
    "        self.p2 = nn.Dense(c2, activation=\"sigmoid\")\n",
    "    def forward(self, x):\n",
    "        t1 = nd.softmax(self.p1(x))\n",
    "        t2 = self.p2(t1)\n",
    "        t3 = t2*x\n",
    "        return nd.reshape(t3,(x.shape[0],1,x.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "ctx = d2l.try_all_gpus()\n",
    "\n",
    "net = nn.Sequential(prefix='WheatOr1')\n",
    "net.add(\n",
    "        Attension(32,200),\n",
    "        nn.BatchNorm(axis=1, center=True, scale=True),\n",
    "        nn.Conv1D(16, kernel_size=3, strides=1),\n",
    "        nn.ELU(),\n",
    "        nn.MaxPool1D(pool_size=2, strides=2),\n",
    "        nn.BatchNorm(axis=1, center=True, scale=True),\n",
    "        nn.Conv1D(16, kernel_size=3, strides=1),\n",
    "        nn.ELU(),\n",
    "        nn.BatchNorm(axis=1, center=True, scale=True),\n",
    "        nn.Conv1D(16, kernel_size=3, strides=1),\n",
    "        nn.ELU(),\n",
    "        nn.Dense(512, activation=\"relu\"),nn.BatchNorm(axis=1, center=True, scale=True),\n",
    "        nn.Dense(128, activation=\"relu\"), nn.BatchNorm(axis=1, center=True, scale=True),\n",
    "        nn.Dense(30))\n",
    "net.initialize(init.Normal(sigma=0.01), ctx=ctx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.collect_params().reset_ctx(ctx)\n",
    "net.hybridize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs=500\n",
    "train_lr=0.0005\n",
    "lr_period=100\n",
    "lr_decay=0.1\n",
    "trainer = gluon.Trainer(net.collect_params(), 'adam', {'learning_rate': train_lr})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "attributes": {
     "classes": [],
     "id": "",
     "n": "12"
    }
   },
   "outputs": [],
   "source": [
    "train_CNN_class(train_iter, val_iter, net, loss, trainer, ctx, train_epochs,lr_period,lr_decay, 0.93)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = evaluate_accuracy(train_iter, net, ctx)\n",
    "val_acc = evaluate_accuracy(val_iter, net, ctx)\n",
    "test_acc = evaluate_accuracy(pre_iter, net, ctx)\n",
    "print('train_acc','val_acc','test_acc')\n",
    "print(train_acc,val_acc,test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
